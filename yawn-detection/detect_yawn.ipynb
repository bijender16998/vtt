{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7dca687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36f67087",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector() #For detecting faces\n",
    "landmark_path=\"shape_predictor_68_face_landmarks.dat\" \n",
    "#Path of the file - if stored in the same directory. Else, give the relative path\n",
    "predictor = dlib.shape_predictor(landmark_path) #For identifying landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24caefdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtaining Facial Landmark coordinates\n",
    "def get_facial_landmarks(image):\n",
    "    face = detector(image, 1)\n",
    "    #Detecting faces in image\n",
    "    if len(face) > 1:\n",
    "        return \"Multiple faces detected in the frame!!\"\n",
    "    if len(face) == 0:\n",
    "        return \"No face detected in the frame!!\"\n",
    "    #Return the coordinates\n",
    "    #Predictor identifies all the 68 landmarks for the detected face\n",
    "    return np.matrix([[pred.x, pred.y] for pred in predictor(image, face[0]).parts()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "934594bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drawing the landmarks : yellow in color \n",
    "def landmarks_annotation(image, facial_landmarks):\n",
    "    #Different image window for facial landmarks\n",
    "    image = image.copy()\n",
    "    for coord, p in enumerate(facial_landmarks):\n",
    "        #Extracting coordinate values and the location / matrix of the coordinates\n",
    "        position = (p[0, 0], p[0, 1])\n",
    "        #Identify and draw the facial landmarks\n",
    "        cv2.putText(image, str(coord), position, cv2.FONT_HERSHEY_COMPLEX, 0.3, (0, 255, 255))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e3864b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Landmark coordinates for upper lip identified in the face \n",
    "def upperlip(facial_landmarks):\n",
    "    ulip = []\n",
    "    #create an array to store the landmark coordinates of the upper lip\n",
    "    for i in range(50,53):\n",
    "        #The range is predefined in \"shape_predictor_68_face_landmarks.dat\"\n",
    "        ulip.append(facial_landmarks[i])\n",
    "    for i in range(61,64):\n",
    "        #The range is predefined in \"shape_predictor_68_face_landmarks.dat\"\n",
    "        ulip.append(facial_landmarks[i])\n",
    "    #Locate the mean value of the upper lip coordinates\n",
    "    ulip_mean = np.mean(ulip, axis=0)\n",
    "    return int(ulip_mean[:,1])#centroid value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348a3409",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Landmark coordinates for lower lip identified in the face \n",
    "def lowerlip(facial_landmarks):\n",
    "    llip = []\n",
    "    #create an array to store the landmark coordinates of the lower lip\n",
    "    for i in range(65,68):\n",
    "        #The range is predefined in \"shape_predictor_68_face_landmarks.dat\"\n",
    "        llip.append(facial_landmarks[i])\n",
    "    for i in range(56,59):\n",
    "        #The range is predefined in \"shape_predictor_68_face_landmarks.dat\"\n",
    "        llip.append(facial_landmarks[i])\n",
    "    #Locate the mean value of the lower lip coordinates\n",
    "    llip_mean = np.mean(llip, axis=0)\n",
    "    return int(llip_mean[:,1])#centroid value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410eaf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect the yawning activity\n",
    "def yawning(image):\n",
    "    #Obtain the facial Landmark coordinates\n",
    "    facial_landmarks = get_facial_landmarks(image)\n",
    "    if type(facial_landmarks) == str:\n",
    "        return image, 0\n",
    "    #Obtain the frame / image with annotated facial landmarks\n",
    "    landmarks_image = landmarks_annotation(image, facial_landmarks)\n",
    "    #Obtain Lip centroids\n",
    "    upperlip_centroid = upperlip(facial_landmarks)\n",
    "    lower_lip_centroid = lowerlip(facial_landmarks)\n",
    "    #Calculate the distance between the centroids\n",
    "    lips_dist = abs(upperlip_centroid - lower_lip_centroid)\n",
    "    return landmarks_image, lips_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd14e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "yawn_status = False \n",
    "yawn_count = 0\n",
    "while True:\n",
    "    _, image_frame = video_capture.read()\n",
    "    #Identify the yawning activity\n",
    "    image_frame = cv2.cvtColor(image_frame, cv2.COLOR_BGR2GRAY)\n",
    "    landmarks_image, lips_dist = yawning(image_frame)\n",
    "    #Update the yawn status\n",
    "    previous_status = yawn_status\n",
    "    #comes under while loop\n",
    "    #lips distance is subjective and changes from subject to subject based on their facial structures\n",
    "    if lips_dist > 25:\n",
    "        yawn_status = True\n",
    "        output_text = \" Number of Yawns: \" + str(yawn_count + 1)\n",
    "        cv2.putText(image_frame, \"You are yawning\", (50,450), cv2.FONT_HERSHEY_COMPLEX, 1,(255,255,0))\n",
    "        cv2.putText(image_frame, output_text, (50,50), cv2.FONT_HERSHEY_COMPLEX, 1,(0,0,255))\n",
    "        \n",
    "    else:\n",
    "        yawn_status = False \n",
    "         \n",
    "    if previous_status == True and yawn_status == False:\n",
    "        yawn_count += 1\n",
    "        \n",
    "    cv2.imshow('Facial Landmarks',landmarks_image)\n",
    "    cv2.imshow('Yawning Activity Detection', cv2.cvtColor(image_frame, cv2.COLOR_BGR2RGB) )\n",
    "    if cv2.waitKey(1)  & 0xFF == ord('q'):\n",
    "        break\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f9d481",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde97943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d267ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e56246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
